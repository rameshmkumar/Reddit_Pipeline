{\rtf1\ansi\ansicpg1252\cocoartf2821
\cocoatextscaling0\cocoaplatform0{\fonttbl\f0\fswiss\fcharset0 Helvetica;}
{\colortbl;\red255\green255\blue255;}
{\*\expandedcolortbl;;}
\margl1440\margr1440\vieww11520\viewh8400\viewkind0
\pard\tx720\tx1440\tx2160\tx2880\tx3600\tx4320\tx5040\tx5760\tx6480\tx7200\tx7920\tx8640\pardirnatural\partightenfactor0

\f0\fs24 \cf0 1. Creating project folder\
\
\
2. Creating venv\
Python -m vent venv\
Source vent/bin/activate\
\
\
3. Installing package requirements\
Pip install raw os doting time date time\
\
4. Load_dotenv()\
\
\
Create\
\
CLIENT_ID=os.getenv('REDDIT_CLIENT_ID')\
CLIENT_SECRET=os.getenv('REDDIT_CLIENT_SECRET')\
USER_AGENT=os.getenv('REDDIT_CLIENT_AGENT')\
USERNAME=os.getenv('REDDIT_USERNAME')\
PASSWORD=os.getenv('REDDIT_PASSWORD')\
\
#all() takes a iterable list and checks if all the elements are truthy\
if not all([CLIENT_ID,CLIENT_SECRET,USER_AGENT,USERNAME,PASSWORD]):\
    print("Error: Missing reddit credentials in .env file")\
else:\
    print("credentials loaded successfully")\
\
\
#let's try if we can authenticate our credentials with reddit\
#PRAW - Python REDDIT API WRAPPER\
#Creating instance with "praw.Reddit()". client_id,client_secret,user_agent,username,password are the parameters\
try:\
    reddit=praw.Reddit(client_id=CLIENT_ID, \
                       client_secret=CLIENT_SECRET,\
                       user_agent=USER_AGENT,\
                       username=USERNAME,\
                       password=PASSWORD)\
    print(f"Authenticated as : \{reddit.user.me()\}")\
    print("Authentication is suceesful")\
\
except Exception as e:\
    print(f"Error during Reddit authentication")\
    reddit=None\
    exit()\
\
#read_only is a property of PRAW\
\
\
#time_filter (str): Time filter for fetching top posts ('day', 'week', 'month', 'year', 'all')\
#subreddits can be listed as a list\
def extract_reddit_posts(reddit_instance, subreddits, limit=25,time_filter='day'):\
\
    all_posts=[]\
\
    #Printing empty list of all_posts, if reddit_instance was not created properly or reddit_instance is in read only mode\
    if not reddit_instance or reddit_instance.read_only:\
        print("Error: For Reddit instance or reddit_instance's permission")\
    \
    #looking through subreddits's list\
    for subreddit_name in subreddits:\
        try:\
            subreddit=reddit_instance.subreddit(subreddit_name)  #We pull the subreddit\
\
            posts=subreddit.top(time_filter=time_filter,limit=limit)  #From the subreddit, we pull the top posts\
\
            count=0\
\
            for post in posts:\
                all_posts.append(post)\
                count +=1\
            print(f"Fetched \{count\} of posts from r/\{subreddit_name\}")\
            time.sleep(1)\
\
        #This to catch the PRAW error\
        except praw.exceptions.PRAWException as e:\
            print(f"Error fetching from r/dataengineer \{e\}")\
\
            continue         #continue to next subreddit\
\
        #This is to catch the other erros\
        except Exception as e:\
            print(f"Unexpected error was caught \{e\}")\
\
            continue\
\
    print(f"Extraction has been completed. \{len(all_posts)\} posts were extracted")\
\
    return all_posts\
\
    \
\
\
def transform_reddit_data(raw_all_posts):\
\
    if not raw_all_posts:\
        print(f"No post was detected to transform")\
        return None\
    \
    transformed_posts=[]\
\
    for post in raw_all_posts:\
        try:\
                              #'created_utc': datetime.utcfromtimestamp(post.created_utc),\
            post_data=\{'post_id':post.id,\
                   'title':post.title, \
                   'score':post.score, \
                   'num_comments':post.num_comments,\
                   'created_utc': datetime.fromtimestamp(post.created_utc),\
                   'author':post.author,\
                   'subreddit':post.subreddit,\
                   'url': post.url,\
                   'selftext':post.selftext,\
                   'is_self':post.is_self,\
                   'permalink':f"www.reddit.com\{post.permalink\}"\}\
\
            transformed_posts.append(post_data)\
\
        except Exception as e:\
            print(f"processing the post \{e\}")\
            continue\
\
    if not transformed_posts:\
        print(f"No post was transformed")\
\
    df=pd.DataFrame(transformed_posts)\
    print(f"Created dataframe with \{len(df)\} rows")\
    \
    if not df.empty:\
        df['score']=pd.to_numeric(df['score'], errors='coerce').astype('Int64')\
        df['author']=df['author'].astype('str')\
        df['num_comments']=df['num_comments'].astype('Int64')\
        df['is_self']=df['is_self'].astype('bool')\
    return df\
\
\
\
\
\
\
\
\
if __name__=="__main__":\
\
    if reddit:\
        targeted_subreddits=['dataengineering', 'Claude','datascience']\
        post_limit = 10 #per subreddit\
        time_period='week'\
\
        raw_data=extract_reddit_posts(reddit_instance=reddit, \
                                      subreddits=targeted_subreddits, \
                                      limit=post_limit, \
                                      time_filter=time_period)\
\
        if raw_data:\
            \
            transformed_df=transform_reddit_data(raw_data)\
            if transformed_df is not None:\
                print(transformed_df.head(5))\
                transformed_df.info()\
\
                try:\
                    transformed_df.to_csv('transformed_reddit_posts.csv', index=False)\
                except Exception as e:\
                    print(f"Error: while creating CSV file \{e\}")\
            else:\
                print("Couldn't transformed data")\
\
        else:\
            print("Error fetching the posts")\
    else:\
        print("Error authenticating the reddit instance")\
\
\
\
\
\
\'97\'97 Loading into DB logic \'97\'97\
Check if the DB engine is available\
If it's None, log a warning and exit early.\
\
Check if the input DataFrame df is empty or None\
If yes, exit early \'97 there's nothing to load.\
\
Check if the table exists in the database\
\
If it does, fetch all existing post_ids from it.\
\
If it doesn\'92t, log that it doesn\'92t exist and proceed (you'll likely create it on first insert).\
\
Filter df to only include new posts (not already in the table)\
\
Use ~df['post_id'].isin(existing_ids) to find only new rows.\
\
Check if there\'92s anything to load with if df_to_load.empty:\
\uc0\u9989  Yes \'97 this tells you "Did we find any new data?"\
\
If df_to_load is not empty, append the new rows to the database table.\
}